{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns #graphs\nimport matplotlib.pyplot as plt\nplt.rc(\"font\", size=14)\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.impute import SimpleImputer\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n#---------------------------------------------------------------------------------------------------------------------------\n\ndef count_categorical(data,output=True):\n    #cicle through data.columns checking for their types and saving those that have 'object' type in 'categorical'\n    categorical = [var for var in data.columns if data[var].dtype=='object']\n    if(output == True):\n        #the length of categorical is the number of categorical variables\n        print('There are {} categorical variables\\n'.format(len(categorical)))\n    \n        #check No labels per feature\n        for var in categorical:\n            no_unique_values = len(data[var].unique())\n            n_missing_values = data[var].isnull().sum()\n        \n            print(var + \" has \" + str(no_unique_values) +\n                  \" distinct labels, with \" + \n                  str(n_missing_values) + \" missing values representing \" + str( round(data[var].isnull().mean() * 100,2) ) + \"%\" ) \n        \n    return categorical\n    \n#---------------------------------------------------------------------------------------------------------------------------\n    \ndef count_numerical(data,output=True):\n    #cicle through data.columns checking for their types and saving those that have 'object' type in 'categorical'\n    numerical = [var for var in data.columns if data[var].dtype!='object']\n    if (output == True):\n           #the length of categorical is the number of categorical variables\n        print('There are {} numerical variables\\n'.format(len(numerical)))\n\n          #check No labels per feature\n        for var in numerical:\n            print(var + \" has \" +  str(data[var].isnull().sum()) + \" missing values representing \" + str( round(data[var].isnull().mean() * 100,2) ) + \"%\"  ) \n    return numerical\n    \n    \n#---------------------------------------------------------------------------------------------------------------------------\n    \n    \ndef boxplot_hist_numerical_data(data,numerical):\n    for j in range(0,len(numerical)):\n        plt.subplot(1,2,1)\n        data.boxplot(column = numerical[j])\n        \n        plt.subplot(1,2,2)\n        data[numerical[j]].hist().set_xlabel(numerical[j])\n        \n        plt.tight_layout()\n        plt.show()\n        \n#---------------------------------------------------------------------------------------------------------------------------\n\n\ndef heatmap(data,title):\n    correlation = data.corr()\n    plt.figure(figsize=(16,12))\n    plt.title(title)\n    ax = sns.heatmap(correlation, square=True, annot=True, fmt='.2f', linecolor='white')\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n    ax.set_yticklabels(ax.get_yticklabels(), rotation=30)           \n    plt.show()\n#---------------------------------------------------------------------------------------------------------------------------\n\ndef correlation_graphs(data,columns): #takes a bit\n    sns.pairplot(data[columns], kind='scatter', diag_kind='hist', palette='Rainbow')\n    plt.show()\n    \n    \n#---------------------------------------------------------------------------------------------------------------------------\n\ndef absolute_frequency(data,categorical):\n    for var in categorical:\n        print(\"-------------------------------\" + var + \"-------------------------------\")\n        print(data[var].value_counts())\n    \n#---------------------------------------------------------------------------------------------------------------------------\n\ndef relative_frequency(data,categorical):\n    for var in categorical:\n        print(\"-------------------------------\" + var + \"-------------------------------\")\n        print(data[var].value_counts()/np.float(data.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DistributionScaler(BaseEstimator, TransformerMixin):   #transformer into diferent scales or normalization/standartization\n    def __init__(self, strategy = None): # no *args or **kargs      \n        self.strategy = strategy\n        self.estimator = None\n    def fit(self, X):\n        if(self.strategy==\"StandardScaler\"):\n            self.estimator=StandardScaler().fit(X)\n        elif(self.strategy==\"MinMaxScaler\"):\n            self.estimator=MinMaxScaler().fit(X)\n        elif(self.strategy==\"MaxAbsScaler\"):\n            self.estimator=MaxAbsScaler().fit(X)\n        elif(self.strategy==\"RobustScaler\"):\n            self.estimator=RobustScaler(quantile_range=(25, 75)).fit(X)\n        elif(self.strategy==\"PowerTransformer_Yeo_Johnson\"):\n            self.estimator=PowerTransformer(method='yeo-johnson').fit(X)\n        elif(self.strategy==\"PowerTransformer_Box_Cox\"):\n            self.estimator=PowerTransformer(method='box-cox').fit(X)\n        elif(self.strategy==\"QuantileTransformer_Normal\"):\n            self.estimator=QuantileTransformer(output_distribution='normal').fit(X)\n        elif(self.strategy==\"QuantileTransformer_Uniform\"):\n            self.estimator=QuantileTransformer(output_distribution='uniform').fit(X)\n        elif(self.strategy==\"Normalizer\"):\n            self.estimator=Normalizer().fit(X)\n        return self  # nothing else to do  \n    def transform(self, X):      \n        if (self.estimator != None):\n            return self.estimator.transform(X)\n        else:\n            if (isinstance(X,(pd.core.frame.DataFrame))):\n                return X.to_numpy()\n            else:\n                return X\n#-----------------------------------------------------------------------------------------------------------   \n\n\nclass OutlierApproacher(BaseEstimator, TransformerMixin): \n    def __init__(self, strategy = None):#,threshold=3): # add treatment later for removal or imputation, add default/custom threshold = 1.5 for IQR and threshold = 3 for ZScore\n        self.strategy = strategy\n        #self.threshold = threshold\n        self.iqr = None\n        self.q3 = None\n        self.q1 = None\n        self.zscore = None\n    def fit(self, X):\n        if (self.strategy==\"ZScore\"):\n            self.zscore = np.abs(stats.zscore(X))\n        if (self.strategy==\"IQR\"):\n            Q1 = wines.quantile(0.25)\n            Q3 = wines.quantile(0.75)\n            self.iqr = Q3 - Q1\n        return self\n        \n    def transform(self, X):\n        if (self.strategy==\"ZScore\"):\n            return X[(self.zscore < 3).all(axis=1)].to_numpy()\n        if (self.strategy==\"IQR\"):\n            return X[~((X < (Q1 - 1.5 * IQR)) |(X > (Q3 + 1.5 * IQR))).any(axis=1)].to_numpy()\n        else:\n            return X.to_numpy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_train = pd.read_csv('../input/titanic/train.csv')\ndata_test = pd.read_csv('../input/titanic/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numerical = count_numerical(data_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical = count_categorical(data_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"absolute_frequency(data_train,categorical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"relative_frequency(data_train,categorical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxplot_hist_numerical_data(data_train,numerical)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"heatmap(data_train,'Wines')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove name column\ndata_train_cut = data_train.drop([\"Name\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train_cut[\"Family Ties\"] = data_train_cut[\"SibSp\"] + data_train_cut[\"Parch\"]\ndata_train_cut = data_train_cut.drop([\"SibSp\",\"Parch\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows = 4000\ndata_train.sort_values([\"Ticket\"],ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows = 4000\ndata_train.sort_values([\"Name\"],ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows = 4000\ndata_train.sort_values([\"Fare\"],ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_rows = 4000\ndata_train.sort_values([\"Cabin\"],ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.groupby([\"Cabin\"])[\"Fare\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}